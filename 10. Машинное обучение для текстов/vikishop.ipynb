{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc88dc1-62d5-4567-b2a6-bdd5a803874d",
   "metadata": {},
   "source": [
    "# ПРОЕКТ для \"Викишоп\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2889cc-5cff-4b4c-9da2-7a2936e61674",
   "metadata": {},
   "source": [
    "Я работаю в интернет-магазине «Викишоп» и мы запускаем новый сервис: \\\n",
    "Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. \\\n",
    "Назрела необходимость в инструменте, который будет искать токсичные комментарии и отправлять их на модерацию. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2096c-3613-43b5-8dda-8f8d6508ec06",
   "metadata": {},
   "source": [
    "**Цель проекта**: построить модель, которая умеет классифицировать комментарии на позитивные и негативные.\n",
    "- Метрика качества F1 должна быть не меньше 0,75. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91a6f8-2f7c-44d9-828d-8448aa4da34a",
   "metadata": {},
   "source": [
    "**Ход исследования:**\n",
    "\n",
    "*Шаг 1* - Загрузка и подготовка данных;\\\n",
    "*Шаг 2* - Обучение нескольких моделей;\\\n",
    "*Шаг 3* - Вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3165ed-8713-4f89-883e-94c1a01d4e00",
   "metadata": {},
   "source": [
    "## Шаг 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612f4f9-2824-4605-a517-480976c8c7e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torch -q\n",
    "!pip install wordcloud -q\n",
    "!pip install transformers -q\n",
    "!pip install hf_xet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69199820-7a05-46f2-9415-bf57c6b34dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импоритруем pandas для обработки, анализа и структурирования данных\n",
    "import pandas as pd \n",
    "# импоритруем numpy для работы с данными\n",
    "import numpy as np\n",
    "# так же импоритруем matplotlib.pyplot для будущего построения графиков\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm, notebook\n",
    "tqdm.pandas()\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, \n",
    "    train_test_split,\n",
    "    cross_val_score\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from wordcloud import WordCloud\n",
    "from catboost import CatBoostClassifier \n",
    "\n",
    "import torch\n",
    "import transformers \n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3494ae9-2665-40b6-b0c1-0ec31fe62867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем константы:\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa8d54-d83c-4969-a38c-09697cbdc0a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d35e8-6af3-47f1-ae20-9b7466baa936",
   "metadata": {},
   "source": [
    "### 1.1 Загрузим данные из csv-файла в датафрейм c помощью библиотеки pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e33125-7334-443a-ab92-627e3acb272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # открываем наш файл с данными в среде JupiterHUB:\n",
    "    data_toxic = pd.read_csv('/datasets/toxic_comments.csv', index_col = 0) \n",
    "        \n",
    "except: # либо берем данные на ПК для локальной версии Jupiter:\n",
    "    data_toxic = pd.read_csv('C://Users//Voova//datasets//toxic_comments.csv', index_col = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2daf5-488b-4955-b5e5-e1c161b23b95",
   "metadata": {},
   "source": [
    "Описание данных:\\\n",
    "**Признак**\n",
    "- **text** — содержит текст комментария;\n",
    "\n",
    "**Целевой признак**\n",
    "- **toxic** — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd770c0-85cd-4abf-bf24-c26223c5070f",
   "metadata": {},
   "source": [
    "### 1.2 Изучим общую информацию о датафрейме. Выведим первые строки набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19341492-61ec-4cf2-b279-0eb139008b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toxic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea309c-959b-47ae-b175-5944640f2d2b",
   "metadata": {},
   "source": [
    "Перед нами датафрейм на **2** колонки и **159 292** строки. Пропущенные значения отсутствуют. Названия столбцов соответствуют общепринятым нормам. \\\n",
    "Посмотрим первые 5 строчек таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de2b9a-5e09-494b-a769-6648a8bc7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toxic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af29cf-9d4d-4700-8803-cc4314909edb",
   "metadata": {},
   "source": [
    "Данные в таблице соответствуют описанию, типы данных корректные.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002da404-50f7-41ac-8b22-deb2c0895b15",
   "metadata": {},
   "source": [
    "Проверим соотношение токсичных отзывов к нетоксичным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987f7e3-5a2a-4568-8b30-c91b2dced72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = 100 * data_toxic['toxic'].value_counts()[1] /(data_toxic['toxic'].value_counts()[0] + data_toxic['toxic'].value_counts()[1])\n",
    "print(f'Токсичные отзывы составляют: {balance.round(2)} % от всего датасета')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21c4d6-ff3b-4337-93cd-226a4256b0c0",
   "metadata": {},
   "source": [
    "Данные несбалансированы, учтем это в параметре стратификации при разбивке на выборки. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc781f-44c2-48ab-85e5-73903b7ee511",
   "metadata": {},
   "source": [
    "## 1.3 Проверим датасет на дубликаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c13115-3135-423e-a80d-e685886e7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toxic.duplicated().sum() # выведим сумму явных дубликатов:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0281b158-3990-4e8b-808e-8d7397156040",
   "metadata": {},
   "source": [
    "- Дубликаты отсутствуют. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cba375-79dc-418a-ac0b-e08a9f1b4cac",
   "metadata": {},
   "source": [
    "## 1.4 Предобработка текста перед обучением: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebea596-9f54-40f8-92e3-e1b7296ea3da",
   "metadata": {},
   "source": [
    "Перед лемматизированием, нужно оставить в отзыве только латинские символы и пробелы. Чтобы их найти, воспользуемся встроенным модулем `re` (сокр. от regular expressions) в функции очистки текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa9278-496b-4390-996f-576a7834e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    return \" \".join((re.sub(r'[^a-zA-Z]', ' ', text)).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46877d6-d18d-4d32-b8ae-36fb047bb0e6",
   "metadata": {},
   "source": [
    "Добавим в датасет столбец с очищенным текстом: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91590cb4-0a9f-47f3-9e19-eea59877ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toxic['clear_text'] = data_toxic['text'].progress_apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cf58e-2af9-4764-aa10-7b91fff9d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toxic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d178f9-0667-4dd2-a411-fd3ae8e5a5dc",
   "metadata": {},
   "source": [
    "Напишем функцию и произведем лемматизацию текста (приведем слова к их базовой форме).\\\n",
    "Для лемматизации я выбираю библиотеку `spaCy`, так как она уже учитывает предварительную токенизациею, и POS-тегирование. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362d692-d568-4dfb-9abf-452d6aa264ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df92c9d7-2969-4abb-8726-8c4f3c065036",
   "metadata": {},
   "source": [
    "Добавим в датасет столбец с лемматизированным текстом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3ec09-ee5e-498b-b069-69c8610339a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_toxic['lemmatize_text'] = data_toxic['clear_text'].progress_apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3fc0b-ea32-4504-a628-ea878e050333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_toxic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46acf81b-5609-4f06-8fe1-010483bf6d05",
   "metadata": {},
   "source": [
    "### 1.5 Посмотрим на частоту встречающихся токсичных слов:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25c523-46a2-4b70-823d-f782df283920",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_text = \" \".join(data_toxic[data_toxic['toxic'] == 1]['lemmatize_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e73d2-07bf-48a4-ac91-d98512f33ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_word = WordCloud(width = 800, \n",
    "                     height = 400, \n",
    "                     background_color = 'black', \n",
    "                     collocations = False\n",
    "                    ).generate(bad_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c765510-df25-4926-a1e2-acc91bfbe2b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(bad_word, interpolation = 'bilinear')\n",
    "plt.title('Наиболее часто встречающиеся токсичные слова', fontsize = 16)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb285d83-2c06-47f2-9f48-84a1b5d9be6f",
   "metadata": {},
   "source": [
    "Самое популярное токсичное слово обнаружено. Вот, что интересно, а если в описании товара написано, что он `OHUITEL'NIY` (если бы мы были в комментариях RU сегмента - получается комментарий посчитается токсичным ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec132e9-c1e1-40de-bd39-b0d1c25a46da",
   "metadata": {},
   "source": [
    "### Вывод: \n",
    "На этапе загрузки и поготовки данных, мы обнаружили, что в нашем распоряжении датасет на **2** столбца и **159 292** строки, пропуски и дубликаты в данных отсутствуют. \\\n",
    "Текст очищен, лемматизирован и готов к моделированию.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d8161-2003-49f5-a314-ee043bd899a9",
   "metadata": {},
   "source": [
    "## Шаг 2. Обучение нескольких моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16c748-fbf8-49d8-88a2-6834a7bfe69b",
   "metadata": {},
   "source": [
    "### 2.1 Разделение данных на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8820549-83e9-458a-9a20-477d34933895",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_toxic['lemmatize_text']\n",
    "y = data_toxic['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc338b6c-9d17-40da-887e-61ad0336a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                    X,\n",
    "                                                    y, \n",
    "                                                    test_size = 0.25, \n",
    "                                                    random_state = RANDOM_STATE,\n",
    "                                                    stratify = y # так как данные у нас несбалансированы\n",
    "                                                    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6792c8-b743-4160-aca9-d3cebc8b4985",
   "metadata": {},
   "source": [
    "Размеры выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805612a1-202b-46d4-9ed0-8eaa17d1ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape[0])\n",
    "print(y_train.shape[0])\n",
    "print(X_test.shape[0])\n",
    "print(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf52b8-e209-4c86-aa99-f4b6d138ceda",
   "metadata": {},
   "source": [
    "Преобразуем корпус текстов в мешок слов (обозначим стоп слова и составим матрицу): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92608d8a-8849-4b65-953c-9b4ec0fc213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set(nltk_stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812de57-8619-4d64-a69f-eb5fc98fa68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words = stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4342e-d9d6-4354-9f76-ffc184300d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = count_tf_idf.fit_transform(X_train)\n",
    "tf_idf_test = count_tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d440821-15ca-4c3d-b824-3e74dd9213f9",
   "metadata": {},
   "source": [
    "Данные подготовлены, приступим к обучению: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11e91d-dc4d-4acd-89ff-a7e2e6b47350",
   "metadata": {},
   "source": [
    "### 2.2 LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1fe3ec-8a7d-413a-9dd3-6bd09060dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression()\n",
    "params_grid_lr = { \n",
    "    'C': [1, 10],\n",
    "    'max_iter': [150],\n",
    "    'random_state' : [RANDOM_STATE]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5069ddd-bb8c-44f3-b5f5-43e12e039a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_cv = GridSearchCV(\n",
    "                       model_lr, \n",
    "                       params_grid_lr, \n",
    "                       scoring ='f1', \n",
    "                       cv = 3)\n",
    "grid_cv.fit(tf_idf_train, y_train)\n",
    "print('Лучшие параметры: ', grid_cv.best_params_)\n",
    "print('F1 значение на тренеровочной выборке: {:.2f}'.format((grid_cv.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0475fbd-ac78-4b93-8acf-31bff87063e2",
   "metadata": {},
   "source": [
    "Метрика F1 как раз нам подходит, так как данные несбалансированы и нам нужно поймать баланс между *precision* и *recall*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b6e49c-89bb-424c-ad2f-2812d7c85377",
   "metadata": {},
   "source": [
    "### 2.3 CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc57aa-eda1-4dd2-9b03-41330495d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat = CatBoostClassifier()\n",
    "params_grid_cat = {\n",
    "    'n_estimators' : [20, 50, 80],\n",
    "    'random_state' : [RANDOM_STATE],\n",
    "    'max_depth' : [3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba9eb7-cf3d-4538-b3f0-55590f23c7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "grid_cv_cat = GridSearchCV(\n",
    "                           estimator = model_cat, \n",
    "                           param_grid = params_grid_cat, \n",
    "                           scoring ='f1', \n",
    "                           cv = 3\n",
    "                          )\n",
    "grid_cv_cat.fit(tf_idf_train, y_train)\n",
    "print('Лучшие параметры: ', grid_cv_cat.best_params_)\n",
    "print('F1 значение на тренеровочной выборке: {:.2f}'.format((grid_cv_cat.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c9adb-37d4-4f8f-8952-fd6bc6295c1c",
   "metadata": {},
   "source": [
    "Проверим лучшую модель на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae6841-92a1-42fa-9936-6084c1258957",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    " \n",
    "model_lr = LogisticRegression(\n",
    "                              C = 10, \n",
    "                              max_iter = 150, \n",
    "                              random_state = RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_lr.fit(tf_idf_train, y_train)\n",
    "predictions_lr = model_lr.predict(tf_idf_test)\n",
    "print('F1 значение на тестовой выборке: {:.2f}'.format(f1_score(predictions_lr, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2001f7-9a45-4cac-99fa-6517502d3343",
   "metadata": {},
   "source": [
    "Метрика F1 удовлетворяет условию задачи, на тренировочных данных обе модели справляются почти одинаково хорошо - регрессия немного точнее. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb07db5-faeb-4ec8-91a7-457913536747",
   "metadata": {},
   "source": [
    "### Вывод без BERT:\n",
    "В данном исследовании перед нами стояла задача разработать решение, которое позволит классифицировать комментарии на позитивные и негативные.\n",
    "- Нам были предоставлены данные в датафрейме **data_toxic** c **2** столбцами и **159 292** строками. \\\n",
    "Данные предоставлены без пропусков и дубликатов.\n",
    "- Далее мы оставили в тексте только латинские символы и пробелы, воспользовавшись встроенным модулем **re** (сокр. от regular expressions) в функции очистки текста.\n",
    "- После этого произвели лемматизацию текста.\n",
    "- На следующем этапе мы выяснили, что наиболее часто встречающееся токсичное слово - **FUCK**.\n",
    "- После разделения данных на обучающую и тестовые выборки, нами были обучены 2 модели:\n",
    "\n",
    "1. Модель **LogisticRegression()** на тестовых данных показала значение метрики F1 равное **0.77**.\n",
    "2. Модель **CatBoostClassifier()** на тестовых данных показала значение метрики F1 равное **0.73**.\n",
    "\n",
    "- На тренировочных данных протестировали лучшую модель, где *LogisticRegression()* показала значение метрики F1 равное **0.78**, что удовлетворяет условию задачи.\n",
    "\n",
    "- Далее пытался попробовать в BERT, но всё мимо :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0c5d0-2794-4360-9c6d-171d62d3df23",
   "metadata": {},
   "source": [
    "### 2.3 BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68407ff-4b8f-42ce-9101-594199d2ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # открываем наш файл с данными в среде JupiterHUB:\n",
    "    data_bert = pd.read_csv('/datasets/toxic_comments.csv', index_col = 0) \n",
    "        \n",
    "except: # либо берем данные на ПК для локальной версии Jupiter:\n",
    "    data_bert = pd.read_csv('C://Users//Voova//datasets//toxic_comments.csv', index_col = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4f52d-d5cd-4cb9-ae9b-031b8ad99fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем токенизатор\n",
    "#model_name = \"unitary/toxic-bert\"\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "#tokenized = data_bert['text'].apply(\n",
    "#    lambda x: tokenizer.encode(x, add_special_tokens = True))\n",
    "\n",
    "#max_len = 0\n",
    "#for i in tokenized.values:\n",
    "#    if len(i) > max_len:\n",
    "#        max_len = len(i)\n",
    "\n",
    "#padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "#attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c61e8-9e1d-4451-9b3b-dee6da015f82",
   "metadata": {},
   "source": [
    "data_bert = data_bert.sample(2000, random_state = 42)\n",
    "data_bert['tokenized_text'] = data_bert['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512)\n",
    ")\n",
    "max_len = 512\n",
    "data_bert['padded_text'] = data_bert['tokenized_text'].apply(\n",
    "    lambda x: x + [0] * (max_len - len(x))\n",
    ")\n",
    "data_bert['attention_mask'] = data_bert['padded_text'].apply(\n",
    "    lambda x: [1 if token != 0 else 0 for token in x]\n",
    ")\n",
    "padded = np.array(data_bert['padded_text'].tolist())\n",
    "attention_mask = np.array(data_bert['attention_mask'].tolist())\n",
    "\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size + 1)):\n",
    "    batch_padded = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch_padded, attention_mask=attention_mask_batch)\n",
    "    \n",
    "    embeddings.append(batch_embeddings[0][:, 0, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96599ee8-8042-4ee0-8a5c-0b43cb35de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# токенизация\n",
    "encodings = tokenizer(\n",
    "    data_bert['text'].tolist(),\n",
    "    padding = True,\n",
    "    truncation = True,\n",
    "    max_length = 512,\n",
    "    return_tensors = 'pt'\n",
    ")\n",
    "\n",
    "batch_size = 50\n",
    "embeddings = []\n",
    "\n",
    "# обработка батчами\n",
    "for i in notebook.tqdm(range(0, len(data_bert), batch_size)):\n",
    "    batch_input_ids = encodings['input_ids'][i:i+batch_size]\n",
    "    batch_attention_mask = encodings['attention_mask'][i:i+batch_size]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids = batch_input_ids,\n",
    "            attention_mask = batch_attention_mask\n",
    "        )\n",
    "        # получение [CLS] эмбеддингов\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(cls_embeddings.numpy())\n",
    "\n",
    "# соберём все эмбеддинги в матрицу признаков вызовом функции concatenate()\n",
    "features = np.concatenate(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce42a0-9ae8-4fef-a3f5-aaaf75d03b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "y = data_bert['toxic']\n",
    " \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                    X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.5, \n",
    "                                                    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f728dcb-3133-4890-a7da-3f3889ad1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    " \n",
    "model = LogisticRegression(random_state = 42)\n",
    "# обучим модель\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print('F1 значение на тестовой выборке: {:.2f}'.format(f1_score(predictions, y_test)))"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 16869,
    "start_time": "2025-08-20T15:10:14.765Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-20T15:10:31.637Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-20T15:10:31.639Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-20T15:10:31.653Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-20T15:10:31.655Z"
   },
   {
    "duration": 1007,
    "start_time": "2025-08-20T15:10:37.976Z"
   },
   {
    "duration": 23,
    "start_time": "2025-08-20T15:10:40.147Z"
   },
   {
    "duration": 13,
    "start_time": "2025-08-20T15:10:45.798Z"
   },
   {
    "duration": 12,
    "start_time": "2025-08-20T15:10:45.963Z"
   },
   {
    "duration": 6,
    "start_time": "2025-08-20T15:10:46.998Z"
   },
   {
    "duration": 8,
    "start_time": "2025-08-20T15:10:47.754Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-20T15:10:48.088Z"
   },
   {
    "duration": 16,
    "start_time": "2025-08-20T15:10:48.268Z"
   },
   {
    "duration": 12,
    "start_time": "2025-08-20T15:10:48.337Z"
   },
   {
    "duration": 1285,
    "start_time": "2025-08-20T15:10:49.128Z"
   },
   {
    "duration": 1946,
    "start_time": "2025-08-20T15:10:50.415Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-20T15:10:52.363Z"
   },
   {
    "duration": 13,
    "start_time": "2025-08-20T15:10:52.374Z"
   },
   {
    "duration": 964,
    "start_time": "2025-08-20T15:10:59.061Z"
   },
   {
    "duration": 30,
    "start_time": "2025-08-20T15:11:00.027Z"
   },
   {
    "duration": 20554,
    "start_time": "2025-08-20T15:11:09.060Z"
   },
   {
    "duration": 915,
    "start_time": "2025-08-20T15:11:38.423Z"
   },
   {
    "duration": 12320,
    "start_time": "2025-08-20T15:11:39.340Z"
   },
   {
    "duration": 23,
    "start_time": "2025-08-20T15:11:51.663Z"
   },
   {
    "duration": 133,
    "start_time": "2025-08-20T15:12:04.696Z"
   },
   {
    "duration": 28040,
    "start_time": "2025-08-20T15:12:24.216Z"
   },
   {
    "duration": 977,
    "start_time": "2025-08-20T15:12:52.258Z"
   },
   {
    "duration": 26,
    "start_time": "2025-08-20T15:12:53.237Z"
   },
   {
    "duration": 6,
    "start_time": "2025-08-20T15:13:09.317Z"
   },
   {
    "duration": 933,
    "start_time": "2025-08-20T15:13:10.495Z"
   },
   {
    "duration": 26,
    "start_time": "2025-08-20T15:13:11.430Z"
   },
   {
    "duration": 11413,
    "start_time": "2025-08-20T15:13:12.641Z"
   },
   {
    "duration": 126021,
    "start_time": "2025-08-20T15:13:24.056Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-20T15:15:30.079Z"
   },
   {
    "duration": 301,
    "start_time": "2025-08-20T15:15:30.155Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-20T15:15:38.921Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-20T15:15:43.270Z"
   },
   {
    "duration": 6,
    "start_time": "2025-08-20T15:15:46.608Z"
   },
   {
    "duration": 675,
    "start_time": "2025-08-20T15:15:53.074Z"
   },
   {
    "duration": 5470,
    "start_time": "2025-08-20T15:15:54.648Z"
   },
   {
    "duration": 1083,
    "start_time": "2025-08-20T15:16:50.566Z"
   },
   {
    "duration": 20,
    "start_time": "2025-08-20T15:16:51.651Z"
   },
   {
    "duration": 5392,
    "start_time": "2025-08-20T15:16:51.673Z"
   },
   {
    "duration": 17581,
    "start_time": "2025-08-20T15:16:57.068Z"
   },
   {
    "duration": 35,
    "start_time": "2025-08-20T15:17:14.651Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-20T15:17:14.688Z"
   },
   {
    "duration": 0,
    "start_time": "2025-08-20T15:17:14.694Z"
   },
   {
    "duration": 13,
    "start_time": "2025-08-20T15:17:17.488Z"
   },
   {
    "duration": 5576,
    "start_time": "2025-08-20T15:17:20.247Z"
   },
   {
    "duration": 399052,
    "start_time": "2025-08-20T15:17:25.826Z"
   },
   {
    "duration": 77,
    "start_time": "2025-08-20T15:24:04.880Z"
   },
   {
    "duration": 405,
    "start_time": "2025-08-20T15:24:04.959Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
